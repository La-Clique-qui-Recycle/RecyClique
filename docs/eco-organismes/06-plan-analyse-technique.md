# Plan d'Analyse Technique - Phase 2

## Objectif de la Phase

Analyser en profondeur le codebase existant de RecyClique pour identifier pr√©cis√©ment les points d'int√©gration avec le nouveau module √©co-organismes et pr√©parer la phase de d√©veloppement.

**Dur√©e estim√©e** : 2-3 semaines
**Statut** : üìã √Ä PLANIFIER
**Pr√©requis** : Phase 1 (Validation) compl√©t√©e avec succ√®s (GO)

---

## Vue d'Ensemble du Codebase Existant

### Stack Technique Identifi√©

#### Backend
- **Framework** : FastAPI (Python)
- **ORM** : SQLAlchemy
- **Base de donn√©es** : PostgreSQL
- **Migrations** : Alembic
- **Cache** : Redis (d√©tect√© via `core/redis.py`)
- **Authentification** : JWT + syst√®me de permissions personnalis√©

#### Structure des R√©pertoires
```
api/src/recyclic_api/
‚îú‚îÄ‚îÄ api/                    # Endpoints API
‚îÇ   ‚îî‚îÄ‚îÄ api_v1/
‚îÇ       ‚îú‚îÄ‚îÄ api.py          # Router principal
‚îÇ       ‚îî‚îÄ‚îÄ endpoints/      # Endpoints par module
‚îÇ           ‚îú‚îÄ‚îÄ deposits.py
‚îÇ           ‚îú‚îÄ‚îÄ cash_sessions.py
‚îÇ           ‚îú‚îÄ‚îÄ categories.py
‚îÇ           ‚îú‚îÄ‚îÄ sales.py
‚îÇ           ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ models/                 # Mod√®les SQLAlchemy
‚îÇ   ‚îú‚îÄ‚îÄ deposit.py
‚îÇ   ‚îú‚îÄ‚îÄ cash_session.py
‚îÇ   ‚îú‚îÄ‚îÄ category.py
‚îÇ   ‚îú‚îÄ‚îÄ sale.py
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ schemas/                # Sch√©mas Pydantic (validation)
‚îÇ   ‚îú‚îÄ‚îÄ deposit.py
‚îÇ   ‚îú‚îÄ‚îÄ dashboard.py
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ services/               # Logique m√©tier
‚îÇ   ‚îú‚îÄ‚îÄ cash_session_service.py
‚îÇ   ‚îú‚îÄ‚îÄ category_service.py
‚îÇ   ‚îú‚îÄ‚îÄ reception_service.py
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ repositories/           # Acc√®s donn√©es (pattern Repository)
‚îÇ   ‚îú‚îÄ‚îÄ reception.py
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ core/                   # Configuration et utilitaires
‚îÇ   ‚îú‚îÄ‚îÄ config.py
‚îÇ   ‚îú‚îÄ‚îÄ database.py
‚îÇ   ‚îú‚îÄ‚îÄ security.py
‚îÇ   ‚îú‚îÄ‚îÄ redis.py
‚îÇ   ‚îî‚îÄ‚îÄ audit.py
‚îî‚îÄ‚îÄ utils/                  # Fonctions utilitaires
    ‚îî‚îÄ‚îÄ ...
```

---

## Analyse des Mod√®les Existants

### 1. Mod√®le `Deposit` (deposits.py)

**Fichier** : `api/src/recyclic_api/models/deposit.py`

**Structure actuelle** :
```python
class Deposit(Base):
    __tablename__ = "deposits"

    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    user_id = Column(UUID(as_uuid=True), ForeignKey("users.id"), nullable=False)
    site_id = Column(UUID(as_uuid=True), ForeignKey("sites.id"), nullable=True)
    telegram_user_id = Column(String, nullable=True)
    audio_file_path = Column(String, nullable=True)

    # Statut et cat√©gorisation
    status = Column(Enum(DepositStatus), nullable=False, default=DepositStatus.PENDING_AUDIO)
    category = Column(Enum(EEECategory), nullable=True)  # ‚ö†Ô∏è Enum EEECategory (DEEE)

    # Poids et description
    weight = Column(Float, nullable=True)  # ‚úÖ Poids en kg - UTILISABLE !
    description = Column(String, nullable=True)

    # IA et transcription
    transcription = Column(Text, nullable=True)
    eee_category = Column(Enum(EEECategory), nullable=True)
    confidence_score = Column(Float, nullable=True)
    alternative_categories = Column(JSON, nullable=True)

    # Timestamps
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    updated_at = Column(DateTime(timezone=True), server_default=func.now(), onupdate=func.now())

    # Relations
    user = relationship("User", back_populates="deposits")
    site = relationship("Site", back_populates="deposits")
```

**Points Cl√©s** :
- ‚úÖ **Champ `weight`** : D√©j√† pr√©sent en Float (kg) - utilisable directement pour flux RECEIVED
- ‚ö†Ô∏è **Cat√©gorie** : Utilise actuellement `EEECategory` (enum DEEE) - **pas compatible** avec cat√©gories g√©n√©riques
- ‚úÖ **Dates** : `created_at` disponible pour filtrer par p√©riode
- ‚úÖ **Statut** : Enum `DepositStatus` avec plusieurs √©tats (PENDING, VALIDATED, COMPLETED)
- ‚ö†Ô∏è **Pas de lien vers cat√©gories g√©n√©riques** : Actuellement focalis√© sur DEEE

**Recommandations pour Int√©gration** :
1. **NE PAS modifier** la structure actuelle de `Deposit`
2. **Cr√©er table d'extension** `deposit_eco_tracking` (comme propos√© dans mod√®le de donn√©es)
3. **Lien 1:1** entre `Deposit` et `DepositEcoTracking` via `deposit_id`
4. Dans `DepositEcoTracking`, stocker :
   - `total_weight_kg` (copie ou agr√©gation du poids)
   - `eco_organism_id` et `eco_category_id` (si mapping applicable)
   - `included_in_declaration_id` (tra√ßabilit√©)

**Requ√™te d'Agr√©gation Flux RECEIVED (Exemple)** :
```python
# Pseudo-code pour comprendre l'int√©gration
def calculate_received_weight_for_period(organism_id, start_date, end_date):
    """
    Agr√®ge les poids des d√©p√¥ts pour une p√©riode donn√©e
    """
    query = (
        db.query(
            CategoryMapping.eco_category_id,
            func.sum(Deposit.weight * CategoryMapping.weight_ratio).label('total_weight')
        )
        .join(DepositEcoTracking, Deposit.id == DepositEcoTracking.deposit_id)
        .join(CategoryMapping,
              and_(
                  DepositEcoTracking.eco_organism_id == CategoryMapping.eco_organism_id,
                  DepositEcoTracking.eco_category_id == CategoryMapping.eco_category_id
              ))
        .filter(
            Deposit.status.in_([DepositStatus.VALIDATED, DepositStatus.COMPLETED]),
            Deposit.created_at >= start_date,
            Deposit.created_at <= end_date,
            CategoryMapping.eco_organism_id == organism_id,
            CategoryMapping.flow_type.in_(['RECEIVED', 'ALL']),
            CategoryMapping.is_active == True
        )
        .group_by(CategoryMapping.eco_category_id)
    )
    return query.all()
```

---

### 2. Mod√®le `CashSession` (cash_session.py)

**Fichier** : `api/src/recyclic_api/models/cash_session.py`

**Structure actuelle** :
```python
class CashSession(Base):
    __tablename__ = "cash_sessions"

    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    operator_id = Column(UUID(as_uuid=True), ForeignKey("users.id"), nullable=False)
    site_id = Column(UUID(as_uuid=True), ForeignKey("sites.id"), nullable=False)
    register_id = Column(UUID(as_uuid=True), ForeignKey("cash_registers.id"), nullable=True)

    # Montants
    initial_amount = Column(Float, nullable=False, default=0.0)
    current_amount = Column(Float, nullable=False, default=0.0)

    # Statut et √©tapes
    status = Column(SAEnum(CashSessionStatus), nullable=False, default=CashSessionStatus.OPEN)
    current_step = Column(SAEnum(CashSessionStep), nullable=True, default=None)

    # Statistiques
    total_sales = Column(Float, nullable=True, default=0.0)
    total_items = Column(Integer, nullable=True, default=0)

    # Dates
    opened_at = Column(DateTime(timezone=True), nullable=False, default=func.now())
    closed_at = Column(DateTime(timezone=True), nullable=True)

    # Relations
    sales = relationship("Sale", back_populates="cash_session", cascade="all, delete-orphan")
    operator = relationship("User", back_populates="cash_sessions")
    site = relationship("Site", back_populates="cash_sessions")
    register = relationship("CashRegister", lazy="joined")
```

**Points Cl√©s** :
- ‚úÖ **Relation `sales`** : Acc√®s aux ventes via relation 1:N
- ‚úÖ **Dates** : `closed_at` disponible pour filtrer les sessions compl√©t√©es
- ‚úÖ **Site** : Possibilit√© de filtrer par site si multi-sites
- ‚ö†Ô∏è **Pas de poids** : Les poids des objets vendus sont dans les `Sale` / `SaleItem`

**√Ä Explorer** :
- Mod√®le `Sale` : Contient-il les objets vendus ?
- Mod√®le `SaleItem` : Lien vers les produits/objets ?
- Y a-t-il un mod√®le `Product` ou `InventoryItem` ?

**Recommandations pour Int√©gration** :
1. **Explorer la cha√Æne** : `CashSession` ‚Üí `Sale` ‚Üí `SaleItem` ‚Üí `Product` (?)
2. **Identifier o√π est le poids** : Probablement dans `Product` ou `SaleItem`
3. **Cr√©er requ√™te d'agr√©gation** similaire √† celle des deposits

**Requ√™te d'Agr√©gation Flux REUSED (Hypoth√®se √† valider)** :
```python
# Pseudo-code hypoth√©tique (√† adapter apr√®s exploration Sale/SaleItem)
def calculate_reused_weight_for_period(organism_id, start_date, end_date):
    """
    Agr√®ge les poids des objets vendus pour une p√©riode donn√©e
    """
    # Hypoth√®se: SaleItem a un lien vers Product qui a un champ weight et category_id
    query = (
        db.query(
            CategoryMapping.eco_category_id,
            func.sum(Product.weight * CategoryMapping.weight_ratio).label('total_weight')
        )
        .join(Sale, SaleItem.sale_id == Sale.id)
        .join(CashSession, Sale.cash_session_id == CashSession.id)
        .join(Product, SaleItem.product_id == Product.id)
        .join(CategoryMapping,
              and_(
                  Product.category_id == CategoryMapping.recyclic_category_id,
                  CategoryMapping.eco_organism_id == organism_id
              ))
        .filter(
            CashSession.status == CashSessionStatus.CLOSED,
            CashSession.closed_at >= start_date,
            CashSession.closed_at <= end_date,
            CategoryMapping.flow_type.in_(['REUSED', 'ALL']),
            CategoryMapping.is_active == True
        )
        .group_by(CategoryMapping.eco_category_id)
    )
    return query.all()
```

---

### 3. Mod√®le `Category` (category.py)

**Fichier** : `api/src/recyclic_api/models/category.py`

**Structure actuelle** :
```python
class Category(Base):
    __tablename__ = "categories"

    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    name = Column(String, unique=True, nullable=False, index=True)
    is_active = Column(Boolean, default=True, nullable=False)

    # Hi√©rarchie
    parent_id = Column(UUID(as_uuid=True), ForeignKey("categories.id"), nullable=True, index=True)
    parent = relationship("Category", remote_side=[id], back_populates="children")
    children = relationship("Category", back_populates="parent")

    # Tarification
    price = Column(Numeric(10, 2), nullable=True)
    max_price = Column(Numeric(10, 2), nullable=True)

    # Affichage
    display_order = Column(Integer, default=0, nullable=False, index=True)
    is_visible = Column(Boolean, default=True, nullable=False, index=True)
    shortcut_key = Column(String, nullable=True)

    # Dates
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    updated_at = Column(DateTime(timezone=True), server_default=func.now(), onupdate=func.now())
```

**Points Cl√©s** :
- ‚úÖ **Hi√©rarchie** : Support parent/child via `parent_id`
- ‚úÖ **Name unique** : Identifiant clair pour mapping
- ‚úÖ **Active/Visible** : Filtres disponibles
- ‚úÖ **UUID** : Compatible avec le mod√®le propos√©
- ‚ö†Ô∏è **Tarification** : Champs `price`/`max_price` - usage actuel √† comprendre

**Recommandations pour Int√©gration** :
1. **Utiliser directement** cette table pour le mapping
2. Table `CategoryMapping` r√©f√©rencera `categories.id` via `recyclic_category_id`
3. **Pas de modification** n√©cessaire sur ce mod√®le

---

### 4. Mod√®les √† Explorer en Priorit√©

#### A. Sale et SaleItem
**Fichiers** : `models/sale.py` et `models/sale_item.py`

**Objectif** :
- Comprendre la structure des ventes
- Identifier le lien vers les produits/objets vendus
- Localiser le champ `weight` (si existant)
- Valider la possibilit√© d'agr√©ger les poids

**Questions** :
1. `Sale` contient-il plusieurs `SaleItem` ?
2. `SaleItem` a-t-il un champ `product_id` ou √©quivalent ?
3. Y a-t-il un mod√®le `Product` distinct ?
4. Le poids est-il stock√© au niveau `SaleItem` ou `Product` ?
5. La cat√©gorie est-elle li√©e au niveau `Product` ?

#### B. Inventory / Stock (si existant)
**Fichier potentiel** : `models/inventory.py` ou `models/product.py`

**Objectif** :
- Identifier la gestion du stock/inventaire
- Comprendre le cycle de vie : D√©p√¥t ‚Üí Stock ‚Üí Vente
- Identifier le flux RECYCLED (objets d√©truits/recycl√©s)

**Questions** :
1. Existe-t-il un mod√®le `InventoryItem` ou `Product` ?
2. Les objets ont-ils un statut `recycled` ou `destroyed` ?
3. Comment est trac√© le passage du d√©p√¥t au stock puis √† la vente ?
4. Y a-t-il une notion de "mouvement" ou "transaction" ?

#### C. Syst√®me de Permissions
**Fichier** : `models/permission.py` et `core/security.py`

**Objectif** :
- Comprendre le syst√®me de permissions actuel
- Identifier comment ajouter les r√¥les √©co-organismes (eco_admin, eco_declarant, etc.)

**Questions** :
1. Permissions bas√©es sur des r√¥les pr√©d√©finis ou flexibles ?
2. Y a-t-il une table `roles` et `user_roles` ?
3. Comment sont v√©rifi√©es les permissions dans les endpoints (d√©corateur, middleware) ?
4. Peut-on facilement ajouter de nouveaux r√¥les ?

---

## Plan d'Audit D√©taill√©

### Semaine 1 : Exploration Modules Core

#### Jour 1 : Mod√®les de Donn√©es
- [ ] **Lire et documenter** tous les mod√®les dans `models/`
- [ ] **Cr√©er sch√©ma ERD** de l'existant (focus sur: deposits, sales, categories, inventory)
- [ ] **Identifier les champs** utilisables pour √©co-organismes (poids, dates, cat√©gories, statuts)
- [ ] **Lister les enums** existants et leur usage

**Livrable** : Document `audit-modeles-existants.md` avec ERD et analyse d√©taill√©e

#### Jour 2 : Services et Logique M√©tier
- [ ] **Analyser** `services/reception_service.py` (gestion des d√©p√¥ts)
- [ ] **Analyser** `services/cash_session_service.py` (gestion des ventes)
- [ ] **Analyser** `services/category_service.py` (gestion des cat√©gories)
- [ ] **Identifier** les m√©thodes r√©utilisables ou √† √©tendre
- [ ] **Comprendre** les patterns de service (injection de d√©pendances, transactions, etc.)

**Livrable** : Document `audit-services-existants.md` avec patterns identifi√©s

#### Jour 3 : API et Endpoints
- [ ] **Analyser** la structure des endpoints (`api/api_v1/endpoints/`)
- [ ] **Comprendre** le router principal (`api/api_v1/api.py`)
- [ ] **Identifier** les patterns de validation (Pydantic schemas)
- [ ] **Comprendre** la gestion des erreurs et exceptions
- [ ] **Analyser** l'authentification et les permissions (d√©corateurs, middleware)

**Livrable** : Document `audit-api-existante.md` avec conventions √† suivre

#### Jour 4-5 : Infrastructure et Outils
- [ ] **Analyser** `core/config.py` : Configuration et variables d'environnement
- [ ] **Analyser** `core/database.py` : Setup base de donn√©es et sessions
- [ ] **Analyser** `core/redis.py` : Utilisation du cache
- [ ] **Analyser** `core/audit.py` : Syst√®me d'audit existant
- [ ] **Explorer** les migrations Alembic existantes (`migrations/versions/`)
- [ ] **Comprendre** le syst√®me de tests (`tests/`)

**Livrable** : Document `audit-infrastructure.md` avec recommandations d'int√©gration

---

### Semaine 2 : Exploration Cha√Ænes Fonctionnelles

#### Jour 1 : Cha√Æne "D√©p√¥t ‚Üí Stock"
**Objectif** : Comprendre le flux RECEIVED

- [ ] **Tracer** le parcours d'un objet depuis son d√©p√¥t
- [ ] **Identifier** o√π et quand le poids est enregistr√©
- [ ] **Comprendre** les statuts et transitions
- [ ] **Localiser** le lien avec les cat√©gories
- [ ] **Valider** si extension `DepositEcoTracking` est viable

**Livrable** : Diagramme de s√©quence "Flux RECEIVED" + analyse

#### Jour 2 : Cha√Æne "Vente"
**Objectif** : Comprendre le flux REUSED

- [ ] **Tracer** le parcours d'un objet vendu
- [ ] **Explorer** mod√®les `Sale`, `SaleItem`, `Product` (si existants)
- [ ] **Identifier** o√π est le poids des objets vendus
- [ ] **Comprendre** le lien entre objet d√©pos√© et objet vendu (tra√ßabilit√©)
- [ ] **Valider** faisabilit√© agr√©gation poids par cat√©gorie

**Livrable** : Diagramme de s√©quence "Flux REUSED" + analyse

#### Jour 3 : Cha√Æne "Recyclage/Destruction"
**Objectif** : Comprendre le flux RECYCLED

- [ ] **Identifier** comment sont marqu√©s les objets recycl√©s/d√©truits
- [ ] **Comprendre** le processus de d√©cision (objet non-vendable)
- [ ] **Localiser** les statuts ou champs pertinents
- [ ] **√âvaluer** si cette information existe ou doit √™tre cr√©√©e

**Livrable** : Analyse flux RECYCLED + recommandations

#### Jour 4 : Syst√®me de Cat√©gories et Mappings
- [ ] **Analyser** l'usage actuel des cat√©gories dans l'app
- [ ] **Identifier** les points de saisie/modification des cat√©gories
- [ ] **Comprendre** la hi√©rarchie et son utilisation
- [ ] **Valider** que les cat√©gories sont bien attach√©es aux objets (deposits, products)
- [ ] **Tester** des requ√™tes d'agr√©gation par cat√©gorie

**Livrable** : Analyse syst√®me de cat√©gories + requ√™tes de test

#### Jour 5 : Permissions et S√©curit√©
- [ ] **Comprendre** le mod√®le de permissions complet
- [ ] **Identifier** comment cr√©er de nouveaux r√¥les
- [ ] **Analyser** Row Level Security (si existant)
- [ ] **Proposer** int√©gration des r√¥les √©co-organismes

**Livrable** : Plan d'int√©gration des permissions

---

### Semaine 3 : Synth√®se et Prototypage

#### Jour 1-2 : Requ√™tes d'Agr√©gation
- [ ] **√âcrire** requ√™tes SQL/SQLAlchemy pour chaque flux (RECEIVED, REUSED, RECYCLED)
- [ ] **Tester** sur donn√©es r√©elles ou fixtures
- [ ] **Mesurer** les performances (EXPLAIN ANALYZE)
- [ ] **Optimiser** avec index si n√©cessaire
- [ ] **Valider** que les calculs sont corrects

**Livrable** : Fichier `aggregation_queries.py` avec requ√™tes document√©es et test√©es

#### Jour 3 : Preuve de Concept (PoC) Technique
- [ ] **Cr√©er** une migration test avec une table simplifi√©e (ex: `eco_test`)
- [ ] **Impl√©menter** un endpoint API minimal pour test
- [ ] **Tester** l'int√©gration avec l'existant (pas de r√©gression)
- [ ] **Valider** le pattern de d√©veloppement

**Livrable** : PoC fonctionnel + retour d'exp√©rience

#### Jour 4 : Documentation des Points d'Int√©gration
- [ ] **Consolider** toutes les analyses pr√©c√©dentes
- [ ] **Cr√©er** document de r√©f√©rence "Points d'Int√©gration"
- [ ] **Lister** les modifications n√©cessaires (minimales) sur l'existant
- [ ] **Identifier** les risques techniques et mitigations

**Livrable** : Document `points-integration-detail.md`

#### Jour 5 : Pr√©sentation et Validation
- [ ] **Pr√©parer** pr√©sentation des findings
- [ ] **Session** avec √©quipe technique (2h)
- [ ] **Valider** l'approche d'int√©gration
- [ ] **Ajuster** le mod√®le de donn√©es propos√© si n√©cessaire
- [ ] **Obtenir** le GO pour phase 3 (prototypage)

**Livrable** : Pr√©sentation + Compte-rendu de validation

---

## Pistes d'Analyse Concr√®tes (Bas√©es sur Exploration Initiale)

### Piste 1 : Extension du Mod√®le Deposit

**Constat** :
Le mod√®le `Deposit` actuel utilise un enum `EEECategory` sp√©cifique aux DEEE, incompatible avec un syst√®me de cat√©gories g√©n√©riques.

**Hypoth√®se** :
Cr√©er une table d'extension `DepositEcoTracking` en relation 1:1 avec `Deposit`.

**Validation n√©cessaire** :
1. ‚úÖ V√©rifier qu'il n'y a **pas d√©j√†** de lien entre `Deposit` et `Category`
2. ‚úÖ Confirmer que `weight` dans `Deposit` est **toujours renseign√©** pour objets tra√ßables
3. ‚ö†Ô∏è Identifier si certains d√©p√¥ts **n'ont pas de poids** (et pourquoi)
4. ‚úÖ Valider que `created_at` est fiable pour filtrage par p√©riode

**Requ√™te de test** :
```sql
-- V√©rifier la couverture du champ weight
SELECT
    COUNT(*) as total_deposits,
    COUNT(weight) as deposits_with_weight,
    COUNT(*) - COUNT(weight) as deposits_without_weight,
    AVG(weight) as avg_weight,
    MIN(weight) as min_weight,
    MAX(weight) as max_weight
FROM deposits
WHERE status IN ('validated', 'completed');
```

**Action** :
- [ ] Ex√©cuter requ√™te de test
- [ ] Analyser les r√©sultats
- [ ] D√©cider si `DepositEcoTracking` est n√©cessaire ou si on peut utiliser directement `Deposit`

---

### Piste 2 : Cha√Æne Sale ‚Üí Product/Category

**Constat** :
Le mod√®le `CashSession` a une relation vers `Sale`, mais la structure compl√®te `Sale ‚Üí SaleItem ‚Üí Product` doit √™tre confirm√©e.

**Hypoth√®se** :
Il existe une cha√Æne `CashSession ‚Üí Sale ‚Üí SaleItem ‚Üí Product` o√π `Product` a un champ `weight` et `category_id`.

**Validation n√©cessaire** :
1. ‚ö†Ô∏è **Lire** `models/sale.py` et `models/sale_item.py`
2. ‚ö†Ô∏è **Identifier** si mod√®le `Product` existe (ou √©quivalent)
3. ‚ö†Ô∏è **Localiser** le champ `weight` dans la cha√Æne
4. ‚ö†Ô∏è **V√©rifier** le lien avec `Category`
5. ‚ö†Ô∏è **Comprendre** si objets vendus = objets d√©pos√©s (tra√ßabilit√©)

**Requ√™te de test** (√† adapter) :
```sql
-- Hypoth√®se √† valider
SELECT
    cs.id as session_id,
    cs.closed_at,
    COUNT(s.id) as nb_sales,
    SUM(si.quantity) as total_items,
    SUM(p.weight * si.quantity) as total_weight  -- Si cette structure existe
FROM cash_sessions cs
JOIN sales s ON s.cash_session_id = cs.id
JOIN sale_items si ON si.sale_id = s.id
JOIN products p ON p.id = si.product_id  -- √Ä valider
WHERE cs.status = 'closed'
GROUP BY cs.id, cs.closed_at;
```

**Actions** :
- [ ] Lire fichiers `sale.py` et `sale_item.py`
- [ ] Chercher mod√®le `Product` ou √©quivalent
- [ ] Adapter requ√™te de test
- [ ] Valider faisabilit√© agr√©gation

---

### Piste 3 : Flux RECYCLED - Strat√©gies Possibles

**Constat** :
Le flux RECYCLED (objets recycl√©s/d√©truits) n'est pas √©vident dans les mod√®les analys√©s.

**Strat√©gies √† explorer** :

#### Strat√©gie A : Statut sur Deposit
Si les objets non-vendables sont marqu√©s directement dans `Deposit` avec un statut sp√©cifique.

**Validation** :
```sql
-- Lister les statuts existants et leur fr√©quence
SELECT status, COUNT(*)
FROM deposits
GROUP BY status;
```

**Action** :
- [ ] Identifier si un statut type `recycled`, `destroyed`, `rejected` existe
- [ ] Si oui : Utiliser ce statut pour flux RECYCLED

#### Strat√©gie B : Table s√©par√©e `RecyclingOperation`
Si le recyclage est un processus s√©par√© avec tra√ßabilit√©.

**Validation** :
- [ ] Chercher mod√®le `RecyclingOperation`, `WasteManagement`, ou similaire
- [ ] Analyser sa structure et relations

#### Strat√©gie C : D√©duction (Gisement - R√©emploi)
Si pas de tra√ßabilit√© explicite, calculer par diff√©rence.

**Formule** :
```
Recycl√© = Gisement - R√©emploi
```

**Inconv√©nient** : Moins pr√©cis, ne capture pas les objets encore en stock

**Action** :
- [ ] √âvaluer si cette approximation est acceptable
- [ ] Documenter les limites

---

### Piste 4 : Performance des Agr√©gations

**Constat** :
Les agr√©gations sur plusieurs mois avec mappings peuvent √™tre lourdes.

**Strat√©gie** :
Utiliser des **vues mat√©rialis√©es** ou un **syst√®me de cache**.

**Validation n√©cessaire** :
1. ‚ö†Ô∏è Identifier si vues mat√©rialis√©es sont d√©j√† utilis√©es dans le projet
2. ‚ö†Ô∏è Comprendre la fr√©quence de rafra√Æchissement acceptable
3. ‚ö†Ô∏è Mesurer les temps de r√©ponse des requ√™tes d'agr√©gation
4. ‚ö†Ô∏è √âvaluer Redis pour cache des calculs (TTL de 24h par exemple)

**Approche recommand√©e** :
1. **Phase 1 (MVP)** : Calculs √† la demande (simples, peut √™tre lent)
2. **Phase 2** : Cache Redis avec invalidation intelligente
3. **Phase 3** : Vues mat√©rialis√©es rafra√Æchies quotidiennement

**Actions** :
- [ ] Mesurer temps de calcul sur jeu de donn√©es r√©el (3 mois de donn√©es)
- [ ] Si > 2 secondes : Impl√©menter cache Redis
- [ ] Si > 10 secondes : Consid√©rer vues mat√©rialis√©es

---

## Checklist d'Audit

### Mod√®les de Donn√©es
- [ ] Tous les mod√®les list√©s et document√©s
- [ ] ERD complet cr√©√©
- [ ] Relations entre entit√©s comprises
- [ ] Champs `weight` localis√©s (deposits, products, etc.)
- [ ] Champs de dates identifi√©s pour filtrage par p√©riode
- [ ] Statuts et enums document√©s
- [ ] Contraintes et index analys√©s

### Services et Logique M√©tier
- [ ] Services existants list√©s et analys√©s
- [ ] Patterns de services identifi√©s (injection d√©pendances, transactions)
- [ ] M√©thodes r√©utilisables identifi√©es
- [ ] Points d'extension localis√©s

### API et Endpoints
- [ ] Structure des endpoints comprise
- [ ] Patterns de validation (Pydantic) document√©s
- [ ] Gestion d'erreurs analys√©e
- [ ] Syst√®me d'authentification et permissions compris
- [ ] Conventions de nommage identifi√©es

### Infrastructure
- [ ] Configuration et variables d'environnement document√©es
- [ ] Setup base de donn√©es et sessions compris
- [ ] Utilisation de Redis identifi√©e
- [ ] Syst√®me d'audit existant analys√©
- [ ] Migrations Alembic explor√©es
- [ ] Tests existants analys√©s

### Flux Fonctionnels
- [ ] Flux RECEIVED (d√©p√¥t) trac√© et document√©
- [ ] Flux REUSED (vente) trac√© et document√©
- [ ] Flux RECYCLED (recyclage) identifi√© ou strat√©gie d√©finie
- [ ] Diagrammes de s√©quence cr√©√©s pour chaque flux

### Permissions et S√©curit√©
- [ ] Mod√®le de permissions compris
- [ ] M√©thode d'ajout de nouveaux r√¥les identifi√©e
- [ ] Row Level Security (si existant) analys√©
- [ ] Plan d'int√©gration des r√¥les √©co-organismes d√©fini

### Requ√™tes et Performance
- [ ] Requ√™tes d'agr√©gation √©crites et test√©es pour chaque flux
- [ ] Performances mesur√©es (temps de r√©ponse)
- [ ] Index n√©cessaires identifi√©s
- [ ] Strat√©gie de cache d√©finie si n√©cessaire

### Preuve de Concept
- [ ] Migration test cr√©√©e
- [ ] Endpoint API minimal impl√©ment√©
- [ ] Int√©gration avec existant test√©e (pas de r√©gression)
- [ ] Pattern de d√©veloppement valid√©

---

## Livrables Finaux de Phase 2

√Ä l'issue de cette phase d'analyse technique, les livrables suivants doivent √™tre produits :

1. **üìÑ Rapport d'Audit Complet** (30-50 pages)
   - ERD de l'existant
   - Documentation des mod√®les, services, API
   - Analyse des flux fonctionnels
   - Diagrammes de s√©quence

2. **üó∫Ô∏è Document "Points d'Int√©gration D√©taill√©s"** (10-15 pages)
   - Liste exhaustive des points d'int√©gration
   - Modifications n√©cessaires sur l'existant (si)
   - Risques techniques et mitigations
   - Recommandations d'impl√©mentation

3. **üíª Fichier `aggregation_queries.py`**
   - Requ√™tes SQLAlchemy pour chaque flux
   - Comment√©es et document√©es
   - Test√©es sur donn√©es r√©elles/fixtures
   - Mesures de performance incluses

4. **üß™ Preuve de Concept (PoC)**
   - Code source dans branche `poc/eco-organisms`
   - Migration de test
   - Endpoint API minimal
   - Documentation d'installation et test

5. **üìä Pr√©sentation Findings** (Slides)
   - Synth√®se des analyses
   - Sch√©mas et diagrammes
   - Recommandations cl√©s
   - Next steps

6. **üìã Plan de D√©veloppement Ajust√©** (v2)
   - Mise √† jour du plan initial bas√© sur findings
   - S√©quen√ßage des sprints ajust√©
   - Estimation des charges revue
   - Risques techniques identifi√©s et mitig√©s

---

## Risques et Mitigations

### Risque 1 : Flux RECYCLED non trac√©
**Impact** : Impossibilit√© de d√©clarer ce flux √† eco-maison
**Probabilit√©** : MOYENNE
**Mitigation** :
- Option A : Ajouter champ de statut ou table d√©di√©e (d√©veloppement additionnel)
- Option B : Utiliser calcul par diff√©rence (moins pr√©cis mais rapide)
- Option C : Reporter cette fonctionnalit√© en v2 (d√©clarer seulement RECEIVED et REUSED)

### Risque 2 : Poids non renseign√©s syst√©matiquement
**Impact** : Calculs automatiques incomplets, n√©cessit√© de saisie manuelle
**Probabilit√©** : FAIBLE (champ weight existe)
**Mitigation** :
- Analyse de couverture (combien de deposits ont weight = NULL ?)
- Si < 5% : Acceptable, signaler dans UI
- Si > 5% : Sensibiliser √©quipe terrain √† renseigner poids

### Risque 3 : Performances des agr√©gations insuffisantes
**Impact** : Lenteur de l'application, mauvaise UX
**Probabilit√©** : MOYENNE
**Mitigation** :
- Mesurer d√®s la phase d'audit
- Impl√©menter cache Redis si n√©cessaire
- Utiliser vues mat√©rialis√©es en dernier recours

### Risque 4 : Incompatibilit√© avec architecture existante
**Impact** : Refonte majeure n√©cessaire, d√©lais allong√©s
**Probabilit√©** : FAIBLE
**Mitigation** :
- Audit approfondi en phase 2
- PoC pour valider l'int√©gration
- Approche modulaire (extension, pas modification)

### Risque 5 : Donn√©es historiques inexploitables
**Impact** : Pas de d√©clarations r√©troactives possibles
**Probabilit√©** : MOYENNE
**Mitigation** :
- Analyser qualit√© des donn√©es historiques
- D√©finir date de d√©marrage r√©aliste (ex: T2 2025)
- Documenter limitations

---

## Crit√®res de Succ√®s de la Phase 2

‚úÖ **Audit complet r√©alis√©** (tous les mod√®les, services, API analys√©s)
‚úÖ **Flux RECEIVED et REUSED** clairement identifi√©s et document√©s
‚úÖ **Flux RECYCLED** : Strat√©gie d√©finie (m√™me si non-id√©ale)
‚úÖ **Requ√™tes d'agr√©gation** √©crites, test√©es, et performantes (< 2s)
‚úÖ **PoC technique** fonctionnel et valid√© par √©quipe
‚úÖ **Points d'int√©gration** clairement document√©s
‚úÖ **Risques techniques** identifi√©s avec mitigations
‚úÖ **Plan de d√©veloppement** ajust√© et r√©aliste
‚úÖ **GO de l'√©quipe technique** pour phase 3 (prototypage)

---

**Prochaine √©tape** : [07-plan-prototypage.md](07-plan-prototypage.md) - Phase 3 de Prototypage UI/UX

---

## Notes pour l'√âquipe d'Audit

### Composition √âquipe Recommand√©e
- **1 Backend Senior** : Lead audit, analyse mod√®les et services
- **1 Backend Junior** : Support, tests, requ√™tes SQL
- **1 Architecte** : Validation architecture, performance
- **Disponibilit√© du Tech Lead actuel** : 20-30% pour questions/clarifications

### Outils N√©cessaires
- Acc√®s lecture √† la base de donn√©es (staging ou copie anonymis√©e)
- Environnement de d√©veloppement local fonctionnel
- Outils de diagrammes (draw.io, dbdiagram.io)
- PostgreSQL + pgAdmin ou DBeaver pour analyses SQL

### R√®gles d'Engagement
1. **Ne rien modifier** dans la base de donn√©es de production
2. **Ne rien committer** sur la branche main pendant l'audit
3. **Utiliser branche d√©di√©e** `audit/eco-organisms` pour notes et tests
4. **Documenter au fur et √† mesure** (ne pas attendre la fin)
5. **Poser des questions** au Tech Lead d√®s qu'un point n'est pas clair
6. **Partager les findings** en daily stand-ups (15 min/jour)

---

**Document cr√©√© le** : 2025-11-20
**Version** : 1.0
**Statut** : PROPOSITION - Plan d'audit technique d√©taill√©
**Bas√© sur** : Exploration initiale du codebase RecyClique
